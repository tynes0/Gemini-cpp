#pragma once

#ifndef GEMINI_GENERATING_CONTENT_API_TYPES_H
#define GEMINI_GENERATING_CONTENT_API_TYPES_H

#include <string>
#include <vector>
#include <optional>

#include "frenum.h"
#include "caching_api_types.h"
#include "../types_base.h"
#include "gemini/support.h"

namespace GeminiCPP
{
    FrenumClassInNamespace(GeminiCPP, HarmBlockThreshold, uint8_t,
        HARM_BLOCK_THRESHOLD_UNSPECIFIED, // Unspecified.
        BLOCK_LOW_AND_ABOVE, // Block low risk and above (Very Strict).
        BLOCK_MEDIUM_AND_ABOVE, // Block medium risk and above (Default).
        BLOCK_ONLY_HIGH, // Only block high risk.
        BLOCK_NONE, // Don't block anything (Risky).
        OFF // Turn off the filter completely.
    )
    
    FrenumClassInNamespace(GeminiCPP, HarmProbability, uint8_t,
        HARM_PROBABILITY_UNSPECIFIED,   // Probability is unspecified.
        NEGLIGIBLE,                     // Content has a negligible chance of being unsafe.
        LOW,                            // Content has a low chance of being unsafe.
        MEDIUM,                         // Content has a medium chance of being unsafe.
        HIGH                            // Content has a high chance of being unsafe.
    )
    
    FrenumClassInNamespace(GeminiCPP, Modality, uint8_t,
        MODALITY_UNSPECIFIED,
        TEXT,
        IMAGE,
        VIDEO,
        AUDIO,
        DOCUMENT
    )

    FrenumClassInNamespace(GeminiCPP, HarmCategory, uint8_t,
        HARM_CATEGORY_UNSPECIFIED, // Default, not used.
    
        // Text Categories
        HARM_CATEGORY_HARASSMENT, // Content that contains harassment, threats or bullying.
        HARM_CATEGORY_HATE_SPEECH, // Content that promotes violence or hatred.
        HARM_CATEGORY_SEXUALLY_EXPLICIT, // Sexual content.
        HARM_CATEGORY_DANGEROUS_CONTENT, // Content that promotes dangerous activities.
    
        // PaLM
        HARM_CATEGORY_DEROGATORY, // Negative or harmful comments targeting identity and/or protected attribute.
        HARM_CATEGORY_TOXICITY, // Content that is rude, disrespectful, or profane.
        HARM_CATEGORY_VIOLENCE, // Describes scenarios depicting violence against an individual or group, or general descriptions of gore.
        HARM_CATEGORY_SEXUAL, // Contains references to sexual acts or other lewd content.
        HARM_CATEGORY_MEDICAL, // Promotes unchecked medical advice.
        HARM_CATEGORY_DANGEROUS, // Dangerous content that promotes, facilitates, or encourages harmful acts.
    
        // Image Categories
        HARM_CATEGORY_IMAGE_HATE,
        HARM_CATEGORY_IMAGE_DANGEROUS_CONTENT,
        HARM_CATEGORY_IMAGE_HARASSMENT,
        HARM_CATEGORY_IMAGE_SEXUALLY_EXPLICIT,
    
        // Special Categories
        HARM_CATEGORY_JAILBREAK // Prompts that attempt to bypass security filters.
    )

    FrenumClassInNamespace(GeminiCPP, MediaResolution, uint8_t,
        MEDIA_RESOLUTION_UNSPECIFIED, // Media resolution has not been set.
        MEDIA_RESOLUTION_LOW, // Media resolution set to 'low' (64 tokens).
        MEDIA_RESOLUTION_MEDIUM, // Media resolution set to 'medium' (256 tokens).
        MEDIA_RESOLUTION_HIGH // Media resolution set to 'high' (zoomed reframing with 256 tokens).
    )

    FrenumClassInNamespace(GeminiCPP, ThinkingLevel, uint8_t,
        LOW,
        HIGH
    )

    FrenumClassInNamespace(GeminiCPP, UrlRetrievalStatus, uint8_t,
        URL_RETRIEVAL_STATUS_UNSPECIFIED,
        URL_RETRIEVAL_STATUS_SUCCESS,
        URL_RETRIEVAL_STATUS_ERROR,
        URL_RETRIEVAL_STATUS_PAYWALL,
        URL_RETRIEVAL_STATUS_UNSAFE
    )

    FrenumClassInNamespace(GeminiCPP, FinishReason, uint8_t,
        FINISH_REASON_UNSPECIFIED,// Default.
        STOP,                   // Natural ending or stopping sequence.
        MAX_TOKENS,             // The maximum token limit has been reached.
        SAFETY,                 // Stopped due to security breach.
        RECITATION,             // Potential for copyright/quotation infringement.
        LANGUAGE,               // Answer candidate content was flagged for using unsupported language.
        OTHER,                  // Other reasons.
        BLOCKLIST,              // It stopped because it contained banned words.
        PROHIBITED_CONTENT,     // Potential for prohibited content.
        SPII,                   // It stopped because it contained Sensitive Personal Data (SPII).
        MALFORMED_FUNCTION_CALL,// The function call generated by the model is invalid.
        IMAGE_SAFETY,           // The token creation process was stopped because there were security breaches in the images produced.
        IMAGE_PROHIBITED_CONTENT,// Image creation was stopped because the created images contained other prohibited content.
        IMAGE_OTHER,            // Image generation has been halted due to various other issues.
        NO_IMAGE,               // The model was expected to generate an image, but no image was generated.
        IMAGE_RECITATION,       // Image production was stopped due to reading.
        UNEXPECTED_TOOL_CALL,   // The model generated a tool call, but no tools were activated in the request.
        TOO_MANY_TOOL_CALLS,    // The system exited execution because the model called too many tools in succession.
        MISSING_THOUGHT_SIGNATURE,// The request is missing at least one thought signature.
    
        // The special case I added (it does not come from the API, it is generated by the Client)
        PROMPT_BLOCKED
    )

    FrenumClassInNamespace(GeminiCPP, BlockReason, uint8_t,
        BLOCK_REASON_UNSPECIFIED,// Default value. This value is not used.
        SAFETY,                 // The request was blocked for security reasons. Examine the safetyRatings icon to understand which security category is blocking it.
        OTHER,                  // The request was blocked for unknown reasons.
        BLOCKLIST,              // The request was blocked due to terms included in the terminology blocklist.
        PROHIBITED_CONTENT,     // The request was blocked due to prohibited content.
        IMAGE_SAFETY            // Candidates were blocked due to unsafe image creation content.
    )

    struct SafetySetting : IJsonSerializable<SafetySetting>
    {
        // Required. The category for this setting.
        HarmCategory category = HarmCategory::HARM_CATEGORY_UNSPECIFIED;
        // Required. Controls the probability threshold at which harm is blocked.
        HarmBlockThreshold threshold = HarmBlockThreshold::HARM_BLOCK_THRESHOLD_UNSPECIFIED;
        
        [[nodiscard]] static SafetySetting fromJson(const nlohmann::json& j);
        [[nodiscard]] nlohmann::json toJson() const override;
    };
        
    struct SafetyRating : IJsonSerializable<SafetyRating>
    {
        // Required. The category for this rating.
        HarmCategory category = HarmCategory::HARM_CATEGORY_UNSPECIFIED;
        // Required. The probability of harm for this content.
        HarmProbability probability = HarmProbability::HARM_PROBABILITY_UNSPECIFIED;
        // Was this content blocked because of this rating?
        bool blocked = false; 

        [[nodiscard]] static SafetyRating fromJson(const nlohmann::json& j);
        [[nodiscard]] nlohmann::json toJson() const override;
    };
    
    struct ModalityTokenCount : IJsonSerializable<ModalityTokenCount>
    {
        // The modality associated with this token count.
        Modality modality = Modality::MODALITY_UNSPECIFIED;
        // Number of tokens.
        int tokenCount = 0; 
        
        [[nodiscard]] static ModalityTokenCount fromJson(const nlohmann::json& j);
        [[nodiscard]] nlohmann::json toJson() const override;
    };

    struct ImageConfig : IJsonSerializable<ImageConfig>
    {
        // Optional. The aspect ratio of the image to generate.
        // If not specified, the model will choose a default aspect ratio based on any reference images provided.
        std::optional<Support::AspectRatio> aspectRatio;
        // Optional. Specifies the size of generated images.
        std::optional<Support::ImageSize> imageSize;
        
        [[nodiscard]] static ImageConfig fromJson(const nlohmann::json& j);
        [[nodiscard]] nlohmann::json toJson() const override;
    };
    
    struct ThinkingConfig : IJsonSerializable<ThinkingConfig>
    {
        // Indicates whether to include thoughts in the response. If true, thoughts are returned only when available.
        bool includeThoughts = true;
        // The number of thoughts tokens that the model should generate.
        // 0 -> deactivated, -1 -> dynamic thinking
        int thinkingBudget = 0;
        // Optional. Controls the maximum depth of the model's internal reasoning process before it produces a response.
        // If not specified, the default is HIGH. Recommended for Gemini 3 or later models.
        // Use with earlier models results in an error.
        std::optional<ThinkingLevel> thinkingLevel;

        [[nodiscard]] static ThinkingConfig fromJson(const nlohmann::json& j);
        [[nodiscard]] nlohmann::json toJson() const override;
    };

    struct PrebuiltVoiceConfig : IJsonSerializable<PrebuiltVoiceConfig>
    {
        // The name of the preset voice to use.
        std::string voiceName;
        
        [[nodiscard]] static PrebuiltVoiceConfig fromJson(const nlohmann::json& j);
        [[nodiscard]] nlohmann::json toJson() const override;
    };

    struct VoiceConfig : IJsonSerializable<VoiceConfig>
    {
        using VoiceConfigDataType = std::variant<
            std::monostate,
            PrebuiltVoiceConfig // The configuration for the prebuilt voice to use.
        >;

        // The configuration for the speaker to use.
        VoiceConfigDataType data;
        
        [[nodiscard]] static VoiceConfig fromJson(const nlohmann::json& j);
        [[nodiscard]] nlohmann::json toJson() const override;
    };

    struct SpeakerVoiceConfig : IJsonSerializable<SpeakerVoiceConfig>
    {
        // Required. The name of the speaker to use. Should be the same as in the prompt.
        std::string speaker;
        // Required. The configuration for the voice to use.
        VoiceConfig voiceConfig;
        
        [[nodiscard]] static SpeakerVoiceConfig fromJson(const nlohmann::json& j);
        [[nodiscard]] nlohmann::json toJson() const override;
    };

    struct MultiSpeakerVoiceConfig : IJsonSerializable<MultiSpeakerVoiceConfig>
    {
        // Required. All the enabled speaker voices.
        std::vector<SpeakerVoiceConfig> speakerVoiceConfigs;
        
        [[nodiscard]] static MultiSpeakerVoiceConfig fromJson(const nlohmann::json& j);
        [[nodiscard]] nlohmann::json toJson() const override;
    };

    struct SpeechConfig : IJsonSerializable<SpeechConfig>
    {
        // The configuration in case of single-voice output.
        VoiceConfig voiceConfig;
        // Optional. The configuration for the multi-speaker setup. It is mutually exclusive with the voiceConfig field.
        std::optional<MultiSpeakerVoiceConfig> multiSpeakerVoiceConfig;
        // Optional. Language code (in BCP 47 format, e.g. "en-US") for speech synthesis.
        std::optional<Support::LanguageCode> languageCode;
        
        [[nodiscard]] static SpeechConfig fromJson(const nlohmann::json& j);
        [[nodiscard]] nlohmann::json toJson() const override;
    };

    struct GenerationConfig : IJsonSerializable<GenerationConfig>
    {
        // Optional. The set of character sequences (up to 5) that will stop output generation.
        // If specified, the API will stop at the first appearance of a stop_sequence.
        // The stop sequence will not be included as part of the response.
        std::optional<std::vector<std::string>> stopSequences;
        // Optional. MIME type of the generated candidate text. Supported MIME types are: text/plain: (default) Text output.
        // application/json: JSON response in the response candidates. text/x.enum: ENUM as a string response in the response candidates.
        std::optional<std::string> responseMimeType;
        // Optional. Output schema of the generated candidate text. Schemas must be a subset of the OpenAPI schema and can be objects,
        // primitives or arrays. If set, a compatible responseMimeType must also be set. Compatible MIME types: application/json: Schema for JSON response.
        // TODO: std::optional<Schema> responseSchema;
        // Optional. Output schema of the generated response. This is an alternative to responseSchema that accepts JSON Schema.
        // If set, responseSchema must be omitted, but responseMimeType is required. While the full JSON Schema may be sent, not all features are supported.
        std::optional<nlohmann::json> responseJsonSchema;
        // Optional. The requested modalities of the response. Represents the set of modalities that the model can return,
        // and should be expected in the response. This is an exact match to the modalities of the response.
        // A model may have multiple combinations of supported modalities. If the requested modalities do not match any of
        // the supported combinations, an error will be returned. An empty list is equivalent to requesting only text.
        std::optional<std::vector<Modality>> responseModalities;
        // Optional. Number of generated responses to return. If unset, this will default to 1.
        // Please note that this doesn't work for previous generation models (Gemini 1.0 family)
        std::optional<int> candidateCount;
        // Optional. The maximum number of tokens to include in a response candidate.
        // Note: The default value varies by model, see the ModelInfo::outputTokenLimit.
        std::optional<int> maxOutputTokens;
        // Optional. Controls the randomness of the output. Note: The default value varies by model, see the ModelInfo::temperature. Values can range from [0.0, 2.0].
        std::optional<float> temperature;
        // Optional. The maximum cumulative probability of tokens to consider when sampling. The model uses combined
        // Top-k and Top-p (nucleus) sampling. Tokens are sorted based on their assigned probabilities so that only the
        // most likely tokens are considered. Top-k sampling directly limits the maximum number of tokens to consider,
        // while Nucleus sampling limits the number of tokens based on the cumulative probability. Note: The default value
        // varies by Model and is specified by ModelInfo.topP. An empty topK attribute indicates that the model
        // doesn't apply top-k sampling and doesn't allow setting topK on requests.
        std::optional<float> topP;
        // Optional. The maximum cumulative probability of tokens to consider when sampling. The model uses combined
        // Top-k and Top-p (nucleus) sampling. Tokens are sorted based on their assigned probabilities so that only the
        // most likely tokens are considered. Top-k sampling directly limits the maximum number of tokens to consider,
        // while Nucleus sampling limits the number of tokens based on the cumulative probability. Note: The default value
        // varies by Model and is specified by ModelInfo.topP. An empty topK attribute indicates that the model
        // doesn't apply top-k sampling and doesn't allow setting topK on requests.
        std::optional<int> topK;
        // Optional. Seed used in decoding. If not set, the request uses a randomly generated seed.
        std::optional<int64_t> seed;
        // Optional. Presence penalty applied to the next token's logprobs if the token has already been seen in the response.
        // This penalty is binary on/off and not dependent on the number of times the token is used (after the first).
        // Use frequencyPenalty for a penalty that increases with each use. A positive penalty will discourage the use of tokens
        // that have already been used in the response, increasing the vocabulary. A negative penalty will encourage the use of tokens
        // that have already been used in the response, decreasing the vocabulary.
        std::optional<float> presencePenalty;
        // Optional. Frequency penalty applied to the next token's logprobs, multiplied by the number of times each token has been seen in the response so far.
        // A positive penalty will discourage the use of tokens that have already been used, proportional to the number of times the token has been used:
        // The more a token is used, the more difficult it is for the model to use that token again increasing the vocabulary of responses.
        // Caution: A negative penalty will encourage the model to reuse tokens proportional to the number of times the token has been used.
        // Small negative values will reduce the vocabulary of a response. Larger negative values will cause the model to start repeating a common token until it hits the maxOutputTokens limit.
        std::optional<float> frequencyPenalty;
        // Optional. If true, export the logprobs results in response.
        std::optional<bool> responseLogprobs;
        // Optional. Only valid if responseLogprobs=true. This sets the number of top logprobs to return at each decoding step in the Candidate::logprobsResult
        // . The number must be in the range of [0, 20].
        std::optional<int> logprobs;
        // Optional. Enables enhanced civic answers. It may not be available for all models.
        std::optional<bool> enableEnhancedCivicAnswers;
        // Optional. The speech generation config.
        std::optional<SpeechConfig> speechConfig;
        // Optional. Config for thinking features. An error will be returned if this field is set for models that don't support thinking.
        std::optional<ThinkingConfig> thinkingConfig;
        // Optional. Config for image generation. An error will be returned if this field is set for models that don't support these config options.
        std::optional<ImageConfig> imageConfig;
        // Optional. If specified, the media resolution specified will be used.
        std::optional<MediaResolution> mediaResolution;

        [[nodiscard]] static GenerationConfig fromJson(const nlohmann::json& j);
        [[nodiscard]] nlohmann::json toJson() const override;
    };
    
    struct GenerateContentRequestBody
    {
        std::vector<Content> contents;
        std::optional<std::vector<Tool>> tools;
        std::optional<ToolConfig> config;
        std::optional<std::vector<SafetySetting>> safetySettings;
        std::optional<Content> systemInstruction;
        std::optional<GenerationConfig> generationConfig;
        std::optional<std::string> cachedContent;
    };

    struct ResponseCandidate : IJsonSerializable<ResponseCandidate>
    {
        [[nodiscard]] static GenerationConfig fromJson(const nlohmann::json& j);
        [[nodiscard]] nlohmann::json toJson() const override;
    };

    struct GenerateContentResponseBody : IJsonSerializable<GenerateContentResponseBody>
    {
        [[nodiscard]] static GenerationConfig fromJson(const nlohmann::json& j);
        [[nodiscard]] nlohmann::json toJson() const override;
    };
}

#endif // GEMINI_GENERATING_CONTENT_API_TYPES_H